{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function, with saving results to CSV files, and limited the certain div range, update threshold to 90%, add include_trials\n",
    "def find_and_process_activity_data(base_path, include_trials=None):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory, limiting processing to included trials if specified.\n",
    "    Outputs two CSV files listing eligible and ineligible subfolders with their corresponding\n",
    "    percentages of qualified lines.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    - include_trials (list, optional): List of trial subfolder names to include in the processing.\n",
    "\n",
    "    Returns:\n",
    "    - None: Results are printed directly and saved into CSV files.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    eligible = []\n",
    "    ineligible = []\n",
    "    \n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]\n",
    "            data_subset.loc[:, 'NeuronType'] = data_subset['NeuronType'].str.strip()\n",
    "            if 'WT' not in data_subset['NeuronType'].unique() or data_subset[data_subset['NeuronType'] == 'WT'].empty:\n",
    "                return (\"Missing WT data.\", \"nan\", False)\n",
    "\n",
    "            WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "            WT = WT.dropna(subset=['Active_area'])\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID', 'Well', 'DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_lines = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_lines = 100 - percentage_low_activity_lines\n",
    "            \n",
    "            if percentage_low_activity_lines > 10:\n",
    "                result_message = \"The dataset is not qualified. More than 10% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", False)\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", True)\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", \"nan\", False)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        subfolder_name = root.split(os.sep)[-1]\n",
    "        # Process only specified trials if include_trials is not None\n",
    "        if include_trials is not None and subfolder_name not in include_trials:\n",
    "            continue\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "                if result[2]:\n",
    "                    eligible.append((subfolder_name, result[1]))\n",
    "                else:\n",
    "                    ineligible.append((subfolder_name, result[1]))\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(eligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Eligible_Cohorts.csv'), index=False)\n",
    "    pd.DataFrame(ineligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Ineligible_Cohorts.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDKL5-E6D_T1_C1_05152024: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SYNGAP1_T1_C1_03212024: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 93.75%\n",
      "ADNP_T2_10262023: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "KCNT1_T3_C1_03122024: The dataset is not qualified. More than 10% of lines show low activity (<50%). Percentage of qualified lines: 10.00%\n",
      "ADNP_T3_11072023: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SHANK3_T1_11222023: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "ADNP_T4_C1_06282024: The dataset is qualified. Less than or equal to 10% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CHD8_T2_C1_08252023: The dataset is not qualified. More than 10% of lines show low activity (<50%). Percentage of qualified lines: 82.50%\n"
     ]
    }
   ],
   "source": [
    "# new usage\n",
    "base_path = \"/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/CSRA/QualityCheck/QualityCheck\"\n",
    "include_trials = ['CDKL5-E6D_T1_C1_05152024', 'SYNGAP1_T1_C1_03212024',\n",
    "       'ADNP_T2_10262023', 'KCNT1_T3_C1_03122024', \n",
    "        'ADNP_T3_11072023', 'SHANK3_T1_11222023',\n",
    "       'ADNP_T4_C1_06282024', 'CHD8_T2_C1_08252023'] # no 'KCNT1_T1_08082023','SPTAN1_T1_07192023'\n",
    "find_and_process_activity_data(base_path, include_trials=include_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function, with saving results to CSV files, and limited the certain div range\n",
    "def find_and_process_activity_data(base_path):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory. Outputs two CSV files listing eligible and ineligible subfolders\n",
    "    with their corresponding percentages of qualified lines.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Results are printed directly and saved into CSV files.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    eligible = []\n",
    "    ineligible = []\n",
    "    \n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]\n",
    "            data_subset.loc[:, 'NeuronType'] = data_subset['NeuronType'].str.strip()\n",
    "            if 'WT' not in data_subset['NeuronType'].unique() or data_subset[data_subset['NeuronType'] == 'WT'].empty:\n",
    "                return (\"Missing WT data.\", \"nan\", False)\n",
    "\n",
    "            WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "            WT = WT.dropna(subset=['Active_area'])\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_lines = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_lines = 100 - percentage_low_activity_lines\n",
    "            \n",
    "            if percentage_low_activity_lines > 50:\n",
    "                result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", False)\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", True)\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", \"nan\", False)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        subfolder_name = root.split(os.sep)[-1]\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "                if result[2]:\n",
    "                    eligible.append((subfolder_name, result[1]))\n",
    "                else:\n",
    "                    ineligible.append((subfolder_name, result[1]))\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(eligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Eligible_Cohorts.csv'), index=False)\n",
    "    pd.DataFrame(ineligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Ineligible_Cohorts.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "syngap_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Qualitycheck/SYNGAP1_T3_C1_08092024/Activity/Compiled_ActivityScan.csv'\n",
    "data=pd.read_csv(syngap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function, with saving results to CSV files, and limited the certain div range\n",
    "def find_and_process_activity_data(base_path):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory. Outputs two CSV files listing eligible and ineligible subfolders\n",
    "    with their corresponding percentages of qualified lines.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Results are printed directly and saved into CSV files.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    eligible = []\n",
    "    ineligible = []\n",
    "    \n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]\n",
    "            data_subset.loc[:, 'NeuronType'] = data_subset['NeuronType'].str.strip()\n",
    "            if 'WT' not in data_subset['NeuronType'].unique() or data_subset[data_subset['NeuronType'] == 'WT'].empty:\n",
    "                return (\"Missing WT data.\", \"nan\", False)\n",
    "\n",
    "            WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "            WT = WT.dropna(subset=['Active_area'])\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_lines = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_lines = 100 - percentage_low_activity_lines\n",
    "            \n",
    "            if percentage_low_activity_lines > 50:\n",
    "                result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", False)\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", True)\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", \"nan\", False)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        subfolder_name = root.split(os.sep)[-1]\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "                if result[2]:\n",
    "                    eligible.append((subfolder_name, result[1]))\n",
    "                else:\n",
    "                    ineligible.append((subfolder_name, result[1]))\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(eligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Eligible_Cohorts.csv'), index=False)\n",
    "    pd.DataFrame(ineligible, columns=['Trial', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Ineligible_Cohorts.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPTAN_1: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CDKL5-E6D_T1_C1_05152024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SYNGAP1_T1_C1_03212024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 93.75%\n",
      "B6J Hyb: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 58.33%\n",
      "SYNGAP1_T3_C1_08092024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 0.00%\n",
      "B6J_T1_02232024_PS: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 58.33%\n",
      "KCNT_T1: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "KCNT1_T3_C1_03122024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 10.00%\n",
      "ADNP_T2: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CHD8_2: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 82.50%\n",
      "CDKL5-E6D_T2_C1_05212024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 31.25%\n",
      "ADNP_T3: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SHANK3_1: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CHD8_T4_C2_02082024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 9.38%\n",
      "ADNP_T4_C1_06282024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CDKL5: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 61.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/mtvvz9t52kxgqcx423vlrhx00000gn/T/ipykernel_17117/2636552377.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "base_path = \"/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck\"\n",
    "find_and_process_activity_data(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIV</th>\n",
       "      <th>Chip_ID</th>\n",
       "      <th>Well</th>\n",
       "      <th>NeuronType</th>\n",
       "      <th>Active_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>12.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>11</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DIV Chip_ID  Well NeuronType  Active_area\n",
       "0      4  M05506     1         WT         0.43\n",
       "1      6  M05506     1         WT         0.24\n",
       "2      7  M05506     1         WT         0.22\n",
       "3     11  M05506     1         WT         0.00\n",
       "4     14  M05506     1         WT         0.00\n",
       "..   ...     ...   ...        ...          ...\n",
       "163    7  M06844     6        HET        12.23\n",
       "164   11  M06844     6        HET         6.24\n",
       "165   14  M06844     6        HET         5.33\n",
       "166   18  M06844     6        HET         2.32\n",
       "167   21  M06844     6        HET          NaN\n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIV</th>\n",
       "      <th>Chip_ID</th>\n",
       "      <th>Well</th>\n",
       "      <th>NeuronType</th>\n",
       "      <th>Active_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>2</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>M05506</td>\n",
       "      <td>2</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>5</td>\n",
       "      <td>HET</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>5</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DIV Chip_ID  Well NeuronType  Active_area\n",
       "4     14  M05506     1         WT         0.00\n",
       "5     18  M05506     1         WT         0.00\n",
       "6     21  M05506     1         WT         0.00\n",
       "11    14  M05506     2         WT         0.00\n",
       "12    18  M05506     2         WT         0.00\n",
       "..   ...     ...   ...        ...          ...\n",
       "159   18  M06844     5        HET         3.51\n",
       "160   21  M06844     5        HET          NaN\n",
       "165   14  M06844     6        HET         5.33\n",
       "166   18  M06844     6        HET         2.32\n",
       "167   21  M06844     6        HET          NaN\n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract WT\n",
    "WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "# drop rows with Active_Area with NaN values\n",
    "WT = WT.dropna(subset=['Active_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M05506', 'M08024', 'M08034', 'M06844'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chip_ids = WT['Chip_ID'].unique()\n",
    "chip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is not qualified. More than 50% of lines show low activity (<50%).\n",
      "Percentage of qualified lines: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the criteria for filtering: lines with Activity_area < 50, filter out if 50% of WT units exhibit lower than 50% activity area\n",
    "\n",
    "criteria = 50\n",
    "\n",
    "# Group by 'Chip_ID','Well','DIV' and calculate the percentage of rows with 'Active_area' < 50 for each combination\n",
    "grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "\n",
    "# Calculate the percentage of lines with low activity\n",
    "percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "\n",
    "# Calculate the percentage of qualified lines\n",
    "percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "\n",
    "# Determine if the dataset is qualified or not based on the criteria\n",
    "if percentage_low_activity_run_ids > 50:\n",
    "    print(\"The dataset is not qualified. More than 50% of lines show low activity (<50%).\")\n",
    "else:\n",
    "    print(\"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50).\")\n",
    "\n",
    "# Print the percentage of qualified lines\n",
    "print(f\"Percentage of qualified lines: {percentage_qualified_run_ids:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chip_ID  Well  DIV\n",
       "M05506   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "M06844   1     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "M08024   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "M08034   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "Name: Active_area, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_datasets(file_paths):\n",
    "    \"\"\"\n",
    "    Batch process multiple datasets to check their qualification based on the criteria \n",
    "    that less than or equal to 50% of unique lines exhibit more than 50% of rows with low activity (<50).\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths (list of str): List of paths to CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with file paths as keys and tuples as values containing the qualification message\n",
    "            and the percentage of qualified lines for each dataset.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Function to process each file and determine qualification\n",
    "    def process_single_file(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        WT = data[data['NeuronType'] == 'WT']\n",
    "        criteria = 50\n",
    "        grouped_by_run = WT.groupby('Run_ID')['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "        percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "        percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "        \n",
    "        if percentage_low_activity_run_ids > 50:\n",
    "            result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50).\"\n",
    "        else:\n",
    "            result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50).\"\n",
    "        \n",
    "        return result_message, percentage_qualified_run_ids\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Process each file and store the result\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            results[path] = process_single_file(path)\n",
    "        except Exception as e:\n",
    "            results[path] = (f\"Error processing file: {str(e)}\", None)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Outputs/SYNGAP_T1_ALL/Activity/Compiled_ActivityScan.csv\n",
      "The dataset is not qualified. More than 50% of lines show low activity (<50).\n",
      "Percentage of qualified lines: 39.29%\n",
      "---\n",
      "File: /Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Outputs/SYNGAP_T1/Activity/Compiled_ActivityScan.csv\n",
      "The dataset is not qualified. More than 50% of lines show low activity (<50).\n",
      "Percentage of qualified lines: 43.75%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Example usage with a list of file paths\n",
    "file_paths = ['/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/SYNGAP_T1_ALL/Activity/Compiled_ActivityScan.csv', \n",
    "              '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/SYNGAP_T1/Activity/Compiled_ActivityScan.csv']  # Add more file paths as needed\n",
    "batch_results = batch_process_datasets(file_paths)\n",
    "\n",
    "# Display results for each file processed\n",
    "for path, (message, percentage) in batch_results.items():\n",
    "    print(f\"File: {path}\")\n",
    "    print(message)\n",
    "    if percentage is not None:\n",
    "        print(f\"Percentage of qualified lines: {percentage:.2f}%\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_process_activity_data(base_path):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Results are printed directly.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            if 'WT' not in data['NeuronType'].unique():\n",
    "                return (\"Missing WT data.\", \"nan%\")\n",
    "\n",
    "            WT = data[data['NeuronType'] == 'WT']\n",
    "            if WT.empty:\n",
    "                return (\"Missing WT data.\", \"nan%\")\n",
    "\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "            \n",
    "            if percentage_low_activity_run_ids > 50:\n",
    "                result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50%).\"\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%).\"\n",
    "            \n",
    "            return (result_message, f\"{percentage_qualified_run_ids:.2f}%\")\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", None)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            subfolder_name = root.split(os.sep)[-1]\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                subfolder_name = root.split(os.sep)[-1]\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNP_Therapy_T2: Missing WT data. Percentage of qualified lines: nan%\n",
      "SYNGAP_T1_ALL: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 34.38%\n",
      "TEST: Missing 'Activity' folder\n",
      "SYNGAP_T1: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 43.75%\n",
      "SYNGAP_Therapy_T1: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 25.00%\n",
      "SYNGAP_T2: Missing WT data. Percentage of qualified lines: nan%\n",
      "TEST_2: Missing 'Activity' folder\n",
      "whatever: Missing WT data. Percentage of qualified lines: nan%\n"
     ]
    }
   ],
   "source": [
    "# Uprated Example usage\n",
    "base_path = \"/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck\"\n",
    "find_and_process_activity_data(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liufanling/miniconda3/envs/my_env_39/lib/python3.9/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140\n",
      "python                : 3.9.18.final.0\n",
      "python-bits           : 64\n",
      "OS                    : Darwin\n",
      "OS-release            : 23.6.0\n",
      "Version               : Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000\n",
      "machine               : arm64\n",
      "processor             : arm\n",
      "byteorder             : little\n",
      "LC_ALL                : None\n",
      "LANG                  : None\n",
      "LOCALE                : None.UTF-8\n",
      "\n",
      "pandas                : 2.2.2\n",
      "numpy                 : 1.26.4\n",
      "pytz                  : 2024.1\n",
      "dateutil              : 2.9.0\n",
      "setuptools            : 72.1.0\n",
      "pip                   : 24.0\n",
      "Cython                : None\n",
      "pytest                : None\n",
      "hypothesis            : None\n",
      "sphinx                : None\n",
      "blosc                 : None\n",
      "feather               : None\n",
      "xlsxwriter            : None\n",
      "lxml.etree            : None\n",
      "html5lib              : None\n",
      "pymysql               : None\n",
      "psycopg2              : None\n",
      "jinja2                : 3.1.4\n",
      "IPython               : 8.18.1\n",
      "pandas_datareader     : None\n",
      "adbc-driver-postgresql: None\n",
      "adbc-driver-sqlite    : None\n",
      "bs4                   : None\n",
      "bottleneck            : 1.3.7\n",
      "dataframe-api-compat  : None\n",
      "fastparquet           : None\n",
      "fsspec                : None\n",
      "gcsfs                 : None\n",
      "matplotlib            : 3.9.1.post1\n",
      "numba                 : None\n",
      "numexpr               : 2.8.7\n",
      "odfpy                 : None\n",
      "openpyxl              : 3.1.5\n",
      "pandas_gbq            : None\n",
      "pyarrow               : None\n",
      "pyreadstat            : None\n",
      "python-calamine       : None\n",
      "pyxlsb                : None\n",
      "s3fs                  : None\n",
      "scipy                 : 1.13.0\n",
      "sqlalchemy            : None\n",
      "tables                : None\n",
      "tabulate              : None\n",
      "xarray                : None\n",
      "xlrd                  : None\n",
      "zstandard             : None\n",
      "tzdata                : 2023.3\n",
      "qtpy                  : None\n",
      "pyqt5                 : None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

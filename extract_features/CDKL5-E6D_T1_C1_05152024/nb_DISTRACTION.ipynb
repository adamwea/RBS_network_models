{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "git_root = !git rev-parse --show-toplevel #get the root of this repo, regardless of where the notebook is run from\n",
    "git_root = git_root[0]\n",
    "#os.chdir(git_root)\n",
    "#print(os.getcwd())\n",
    "sys.path.append(f'{git_root}/extract_features/')\n",
    "from helper_functions import get_list_of_h5_files, process_csv_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def get_list_of_h5_files(h5_parent_dirs, allowed_scan_types=None, **kwargs):\n",
    "    if allowed_scan_types is None:\n",
    "        allowed_scan_types = kwargs.get('sorting_params', {}).get('allowed_scan_types', [''])[0]\n",
    "    \n",
    "    h5_files = []\n",
    "    for h5_parent_dir in h5_parent_dirs:\n",
    "        if h5_parent_dir.endswith('.h5') and allowed_scan_types in h5_parent_dir:\n",
    "            h5_files.append(h5_parent_dir)\n",
    "            continue\n",
    "        for root, dirs, files in os.walk(h5_parent_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.h5') and allowed_scan_types in root:\n",
    "                    h5_files.append(os.path.join(root, file))\n",
    "    return h5_files\n",
    "\n",
    "def process_csv_to_dict(df, h5_parent_dirs, allowed_scan_types=None, allowed_RBS_scan_types=None):\n",
    "    # Initialize the dictionary to hold the structured data\n",
    "    data_dict = defaultdict(dict)\n",
    "    \n",
    "    # Get list of h5 files from the directories\n",
    "    h5_files = get_list_of_h5_files(h5_parent_dirs, allowed_scan_types, allowed_RBS_scan_types=allowed_RBS_scan_types)\n",
    "    \n",
    "    unmatched_rows = []  # List to track rows that couldn't be matched\n",
    "\n",
    "    # Loop over each row in the DataFrame\n",
    "    lowest_run_num = 999999\n",
    "    lowest_run_id = 41092384\n",
    "    for _, row in df.iterrows():\n",
    "        # Convert the date to YYMMDD format\n",
    "        date_str = dt.datetime.strptime(row['Date'], '%m/%d/%Y').strftime('%y%m%d')\n",
    "        chip_id = row['ID']\n",
    "        RBS_scan_type = row['Assay']\n",
    "        source = row['Neuron Source'].split(', ')\n",
    "        run_number = row['Run #']\n",
    "        run_DIV = row['DIV']\n",
    "        # if run_number < lowest_run_num:\n",
    "        #     lowest_run_num = run_number\n",
    "        # run_num_diff = run_number - lowest_run_num\n",
    "\n",
    "        #filter RBS_scan_type\n",
    "        if allowed_RBS_scan_types is not None:\n",
    "            if RBS_scan_type not in allowed_RBS_scan_types:\n",
    "                continue\n",
    "        \n",
    "        # Filter relevant h5 files for this chip_id and date\n",
    "        relevant_files = [f for f in h5_files if chip_id in f and date_str in f]\n",
    "        \n",
    "        if not relevant_files:\n",
    "            # If no relevant files found, add row to unmatched list and continue\n",
    "            unmatched_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        matched = False  # Flag to check if we successfully matched a file\n",
    "        \n",
    "        for h5_file in relevant_files:\n",
    "            # Extract the scan type from the path, it should be the directory name before the chip_id\n",
    "            maxwell_scan_type = h5_file.split('/')[-3]\n",
    "            \n",
    "            if maxwell_scan_type in allowed_scan_types:\n",
    "                # Extract the run ID from the path (6-digit number in the Network folder)\n",
    "                run_id_match = re.search(r'/(\\d{6})/data\\.raw\\.h5', h5_file)\n",
    "                \n",
    "                # if not run_id_match:\n",
    "                #     continue  # If we can't find the run_id, skip this file\n",
    "\n",
    "                run_id = run_id_match.group(1)\n",
    "                if int(run_id) < int(lowest_run_id):\n",
    "                    lowest_run_id = run_id\n",
    "                run_id_diff = int(run_id) - int(lowest_run_id)\n",
    "                \n",
    "                try:\n",
    "                    assert chip_id in h5_file, f\"{chip_id} not in {h5_file}\"  # Assert that the chip_id is in the h5_file path\n",
    "                    assert date_str in h5_file, f\"{date_str} not in {h5_file}\" # Assert that the date_str is in the h5_file path\n",
    "                    \n",
    "                    #run number will be continuous while run_id may not be if there are any cancelled runs\n",
    "                    assert int(run_number) <= int(run_id), f\"{run_number} not less than {run_id}\" # Assert that the run_number is less than or equal to the run_id\n",
    "                    \n",
    "                    #Rules for matching scan types\n",
    "                    # If the scan type is 'Network', it should be present in the allowed_scan_types\n",
    "                    if 'Network' in allowed_scan_types:\n",
    "                        assert 'Network' in maxwell_scan_type\n",
    "                        try: assert 'Network Today' in RBS_scan_type\n",
    "                        except: assert 'Neuronal Unit' in RBS_scan_type\n",
    "                except AssertionError as e:  # If the assertions fail, print the error and continue to the next file\n",
    "                    print(e)\n",
    "                    continue\n",
    "                \n",
    "                # Create a unique chip identifier based on the run ID (e.g., M08018_000120)\n",
    "                chip_id_with_run = f\"{chip_id}_{run_number}\"\n",
    "                \n",
    "                # Insert the structured data into the dictionary\n",
    "                if date_str not in data_dict:\n",
    "                    data_dict[date_str] = {}\n",
    "                \n",
    "                data_dict[date_str][chip_id_with_run] = {\n",
    "                    \"path\": h5_file,\n",
    "                    \"scan_type\": maxwell_scan_type,\n",
    "                    \"RBS_scan_type\": RBS_scan_type,\n",
    "                    \"DIV\": run_DIV,\n",
    "                    \"source\": source\n",
    "                }\n",
    "                matched = True\n",
    "                break  # If a match is found, no need to check further\n",
    "\n",
    "        if not matched:\n",
    "            unmatched_rows.append(row)\n",
    "\n",
    "    # If there are any unmatched rows, print them out\n",
    "    if unmatched_rows:\n",
    "        print(\"Unmatched rows:\")\n",
    "        for row in unmatched_rows:\n",
    "            print(row)\n",
    "    \n",
    "    return dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 not less than 000008\n",
      "13 not less than 000010\n",
      "13 not less than 000011\n",
      "13 not less than 000012\n",
      "36 not less than 000025\n",
      "36 not less than 000026\n",
      "36 not less than 000027\n",
      "36 not less than 000028\n",
      "36 not less than 000033\n",
      "36 not less than 000034\n",
      "36 not less than 000035\n",
      "49 not less than 000045\n",
      "49 not less than 000047\n",
      "49 not less than 000048\n",
      "63 not less than 000058\n",
      "63 not less than 000060\n",
      "63 not less than 000061\n",
      "63 not less than 000062\n",
      "77 not less than 000072\n",
      "77 not less than 000074\n",
      "77 not less than 000075\n",
      "77 not less than 000076\n",
      "95 not less than 000090\n",
      "95 not less than 000092\n",
      "95 not less than 000093\n",
      "110 not less than 000105\n",
      "110 not less than 000107\n",
      "110 not less than 000108\n",
      "110 not less than 000109\n",
      "127 not less than 000122\n",
      "127 not less than 000124\n",
      "127 not less than 000125\n",
      "127 not less than 000126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json #save as json, save the json so I can easily read it in vscode\n",
    "file_paths = [\n",
    "    #'/app/extract_features/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024.csv', #if running in docker\n",
    "    f'{git_root}/extract_features/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024.csv' #if running in vscode\n",
    "]\n",
    "synology_mnt = '/mnt/ben-shalom_nas'\n",
    "#dev_mnt = '/data'\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv(file_path) # Load the CSV file to inspect its contents\n",
    "    h5_parent_dirs = [\n",
    "        f'{synology_mnt}/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024',\n",
    "        #f'{dev_mnt}/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024', #if running in docker\n",
    "        ]\n",
    "    allowed_scan_types = 'Network'\n",
    "    allowed_RBS_scan_types = 'Neuronal Units 9'\n",
    "    extracted_data = process_csv_to_dict(data, h5_parent_dirs, allowed_scan_types, allowed_RBS_scan_types=allowed_RBS_scan_types)\n",
    "    #extracted_data_path = '/app/extract_features/CDKL5-E6D_T1_C1_05152024/extracted_data.json'\n",
    "    extracted_data_path = f'{git_root}/extract_features/CDKL5-E6D_T1_C1_05152024/extracted_data.json'\n",
    "    with open(extracted_data_path, 'w') as json_file:\n",
    "        json.dump(extracted_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamm/miniconda3/envs/netsims/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-30 21:54:23,528 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 21:54:23,529 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,174 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,232 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,275 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,315 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,359 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,400 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,442 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 21:54:24,449 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:01:01,366 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240520/M08018/Network/000013/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:08:01,040 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 22:08:01,041 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240520/M08018/Network/000013/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:08:01,671 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:01,736 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:01,784 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:01,830 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:01,877 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:01,969 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:02,026 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:08:02,050 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:15:21,135 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240523/M08018/Network/000036/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:23:21,533 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 22:23:21,533 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240523/M08018/Network/000036/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:23:22,066 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,130 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,182 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,227 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,273 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,319 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,415 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:23:22,445 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n",
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240528/M08018/Network/000049/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:33:18,314 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:42:45,019 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 22:42:45,021 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240528/M08018/Network/000049/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:42:45,518 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,569 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,611 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,651 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,692 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,733 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,779 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:42:45,793 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:51:02,294 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240531/M08018/Network/000063/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:58:50,419 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 22:58:50,420 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240531/M08018/Network/000063/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 22:58:50,819 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:50,881 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:50,926 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:50,966 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:51,007 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:51,049 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:51,090 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 22:58:51,111 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:06:47,209 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240604/M08018/Network/000077/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:16:30,153 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 23:16:30,154 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240604/M08018/Network/000077/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:16:30,799 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:30,858 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:30,907 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:30,951 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:31,053 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:31,108 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:31,155 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:16:31,159 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:26:01,524 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240607/M08018/Network/000095/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:34:48,134 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 23:34:48,135 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240607/M08018/Network/000095/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:34:48,690 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:48,760 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:48,814 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:48,858 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:48,900 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:48,996 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:49,055 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:34:49,059 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:44:01,245 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240611/M08018/Network/000110/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamm/miniconda3/envs/netsims/lib/python3.8/site-packages/spikeinterface/core/basesorting.py:175: UserWarning: Some spikes exceed the recording's duration! Removing these excess spikes with `spikeinterface.curation.remove_excess_spikes()` Might be necessary for further postprocessing.\n",
      "  warnings.warn(\n",
      "2024-09-30 23:52:00,877 - INFO - Extracting recording details from h5 directories: - mea_processing_library.extract_recording_details\n",
      "2024-09-30 23:52:00,878 - INFO - Scan Type: Network - mea_processing_library.load_recordings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240611/M08018/Network/000110/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:52:01,421 - INFO - MaxTwo Detected. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,489 - DEBUG - Stream ID: well000, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,535 - DEBUG - Stream ID: well001, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,577 - DEBUG - Stream ID: well002, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,620 - DEBUG - Stream ID: well003, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,665 - DEBUG - Stream ID: well004, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,758 - DEBUG - Stream ID: well005, Recording: rec0000 loaded. - mea_processing_library.load_recordings\n",
      "2024-09-30 23:52:01,785 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well well000 as it is not WT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 00:01:47,182 - INFO - Running Kilosort2 spike sorting using Docker Images: rohanmalige/benshalom:v3. - mea_processing_library.benshalom_kilosort2_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting complete for well well001 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240614/M08018/Network/000127/data.raw.h5\n",
      "Skipping well well002 as it is not WT.\n",
      "Skipping well well003 as it is not WT.\n",
      "Sorting complete for well well004 in /mnt/ben-shalom_nas/rbs_maxtwo/rbsmaxtwo/media/rbs-maxtwo/harddisk20tb/CDKL5-E6D_T1_C1_05152024/CDKL5-E6D_T1_C1_05152024/240614/M08018/Network/000127/data.raw.h5\n",
      "Skipping well well005 as it is not WT.\n"
     ]
    }
   ],
   "source": [
    "#sys.path.append('/app/submodules/MEA_Analysis/MEAProcessingLibrary')\n",
    "sys.path.append(f'{git_root}/submodules/MEA_Analysis/MEAProcessingLibrary')\n",
    "import mea_processing_library as MPL\n",
    "\n",
    "# Define the neuron source of interest\n",
    "source_of_interest = \"WT\"\n",
    "\n",
    "# Function to extract paths for the source of interest\n",
    "def extract_paths_for_source(data, source_filter):\n",
    "    filtered_data = []\n",
    "    for date_key, wells_data in data.items():\n",
    "        for well_id, well_info in wells_data.items():\n",
    "            # Check if the source filter exists in the source list\n",
    "            if any(source_filter in s for s in well_info['source']):\n",
    "                filtered_data.append({\n",
    "                    'path': well_info['path'],\n",
    "                    'source': well_info['source']\n",
    "                })\n",
    "    return filtered_data\n",
    "\n",
    "# Extract the data where WT is involved\n",
    "filtered_well_data = extract_paths_for_source(extracted_data, source_of_interest)\n",
    "\n",
    "# Process each well for the selected recordings\n",
    "for well_info in filtered_well_data:\n",
    "    test_h5_path = well_info['path']\n",
    "    \n",
    "    try:\n",
    "        # Load recordings\n",
    "        MaxID, recordings, expected_well_count, rec_counts = MPL.load_recordings(test_h5_path, stream_select=None, logger=None)\n",
    "        \n",
    "        # Process only the wells that are associated with the WT source\n",
    "        for well_key, recording in recordings.items():\n",
    "            \n",
    "            recording = recording['recording_segments'][0]  # Get the first recording segment\n",
    "            # Get the index from the well key to match with the source (e.g., well000 -> index 0, well001 -> index 1)\n",
    "            well_index = int(well_key[-1])  # Assuming the key format is 'well000' to 'well005'\n",
    "            \n",
    "            # Check if the corresponding source for this well is WT\n",
    "            source = well_info['source'][well_index]\n",
    "\n",
    "            # # Path inside the container\n",
    "            # output_folder_in_container = f'/app/extract_features/CDKL5-E6D_T1_C1_05152024/sortings/{well_key}'\n",
    "\n",
    "            # # Create the output folder if it doesn't exist\n",
    "            # if os.path.exists(output_folder_in_container) is False:\n",
    "            #     os.makedirs(output_folder_in_container)\n",
    "\n",
    "            # # Path inside the container\n",
    "            # output_folder_in_container = f'/app/extract_features/CDKL5-E6D_T1_C1_05152024/sortings/'\n",
    "\n",
    "            # # Convert the Docker container path to the host path\n",
    "            # output_folder_on_host = output_folder_in_container.replace('/app', '/home/adamm/workspace/RBS_network_simulations')\n",
    "            \n",
    "            #get well recording info from path\n",
    "            date_str = test_h5_path.split('/')[-5]\n",
    "            chip_id = test_h5_path.split('/')[-4]\n",
    "            scan_type = test_h5_path.split('/')[-3]\n",
    "            run_id = test_h5_path.split('/')[-2]\n",
    "            #output path\n",
    "            output_folder = f'{git_root}/extract_features/CDKL5-E6D_T1_C1_05152024/sortings/{date_str}/{chip_id}/{scan_type}/{run_id}/{well_key}'\n",
    "\n",
    "            #create the output folder if it doesn't exist\n",
    "            if os.path.exists(output_folder) is False:\n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            if source_of_interest in source:\n",
    "                # Now you can use `output_folder_on_host` to pass to the Kilosort container\n",
    "                sorting = MPL.benshalom_kilosort2_docker_image(\n",
    "                    recording, \n",
    "                    output_folder = output_folder, \n",
    "                    #output_folder=output_folder_on_host,  # Host path\n",
    "                    #logger=None\n",
    "                )\n",
    "                print(f\"Sorting complete for well {well_key} in {test_h5_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping well {well_key} as it is not WT.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {test_h5_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract features from the sorted data\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
